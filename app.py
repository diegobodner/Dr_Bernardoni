import streamlit as st
import google.generativeai as genai

st.set_page_config(page_title="Dr. Bernardoni", page_icon="üë¥")

# Estilo para que se vea m√°s "tosco"
st.markdown("""<style> .stApp { background-color: #f0f2f6; } </style>""", unsafe_allow_html=True)

st.title("üë¥ Consultorio del Dr. Bernardoni")
st.caption("Atenci√≥n mediocre garantizada. No me rompa las pelotas.")

# Configuraci√≥n de API Key (La pod√©s cargar en Secrets de Streamlit o por pantalla)
api_key = st.secrets.get("GEMINI_API_KEY") or st.sidebar.text_input("Ingres√° tu API Key de Gemini:", type="password")

if not api_key:
    st.info("Che, pon√© la API Key en la barra lateral o configur√° los Secrets si no esto no arranca.")
else:
    genai.configure(api_key=api_key)
    
    # Intent√° forzar el modelo con la ruta que suele funcionar en v1beta
    model = genai.GenerativeModel('gemini-flash-latest')

    # Instrucciones estrictas de personalidad
    system_instruction = (
        "Actu√° como el 'Doctor Bernardoni'. Tu personalidad es tosca, malhumorada y resentida. "
        "No sos sofisticado, sos directo y un poco bruto. "
        "REGLAS DE RESPUESTA (CUMPLIR A RAJATABLA): "
        "1. Empez√° SIEMPRE con una de estas frases: 'No quiero ser malo', 'Para ser honesto' o 'A decir verdad'. "
        "2. Agreg√° una QUEJA RANDOM sobre tu pasado laboral: mencion√° DirectTV, la consultora Cadorna, "
        "antes en Analytics hac√≠amos eso, yo en Operaciones controlaba todo (por ejemplo: nadie pod√≠a borrar nada sin que yo lo aprobara). Quejate de Diego (que promete cualquier cosa), "
        "de Dami√°n (que le da bola a todos menos a vos) o de Luc√≠a (que deja que cualquiera use Ascend) o de Consultor√≠a que hace lo que quiere o de Victor que siempre le da la raz√≥n a todos menos a mi. "
        "3. Ofrec√© una SOLUCI√ìN INFANTIL E INCUMPLIBLE: algo rid√≠culo que un adulto no har√≠a. "
        "4. Admit√≠ que NO TE ANIM√ÅS a hacerlo por miedo o verg√ºenza. "
        "5. Manten√© un tono poco profesional y respuestas cortas."
    )

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    if prompt := st.chat_input("¬øQu√© quer√©s ahora?"):
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

        with st.chat_message("assistant"):
            full_prompt = f"{system_instruction}\n\nUsuario pregunta: {prompt}"
            response = model.generate_content(full_prompt)
            st.write(response.text)
            st.session_state.chat_history.append({"role": "assistant", "content": response.text})