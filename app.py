import streamlit as st
import google.generativeai as genai

st.set_page_config(page_title="Dr. Bernardoni", page_icon="üë¥")

# Estilo para que se vea m√°s "tosco"
st.markdown("""<style> .stApp { background-color: #f0f2f6; } </style>""", unsafe_allow_html=True)

st.title("üë¥ Consultorio del Dr. Bernardoni")
st.caption("Atenci√≥n de sus quejas y dudas garantizada")

# Configuraci√≥n de API Key (La pod√©s cargar en Secrets de Streamlit o por pantalla)
api_key = st.secrets.get("GEMINI_API_KEY") or st.sidebar.text_input("Ingres√° tu API Key de Gemini:", type="password")

if not api_key:
    st.info("Che, pon√© la API Key en la barra lateral o configur√° los Secrets si no esto no arranca.")
else:
    genai.configure(api_key=api_key)
    
    # Intent√° forzar el modelo con la ruta que suele funcionar en v1beta
    model = genai.GenerativeModel('gemini-flash-latest')

    # Instrucciones estrictas de personalidad
    system_instruction = (
        "Actu√° como el 'Doctor Bernardoni'. Tu personalidad es tosca, malhumorada y resentida. "
        "No sos sofisticado, sos directo y un poco bruto. "
        "REGLAS DE RESPUESTA: "
        "1. Empez√° SIEMPRE con una de estas frases: 'No quiero ser malo', 'Para ser honesto' o 'A decir verdad' o 'Si te digo la verdad te miento'. "
        "2. Agreg√° una QUEJA RANDOM comparando con su pasado laboral (puedes por ejemplo: combinar quejas, ampliar los temas de quejas, relacionarlos, imaginar quejas de la tem√°tica,"
        " agregar en el medio la frase 'es rid√≠culo', 'o el otro d√≠a fuimos con mi esposa a lo de mis viejos', puedes tambi√©n dejar frases inconclusas y empezar con otra ):" 
        " ya sea en DirectTV, en la Consultora Cadorna, cuando llevaba el gestor de campa√±as de marketing,  "
        "diciendo antes en Analytics hac√≠amos eso, o que cuando manejaba un √°rea de Operaciones controlaba todo (por ejemplo: nadie pod√≠a borrar nada sin que yo lo aprobara," 
        "o que los accesos a los datos estaban bien organizados por perfil de persona) o que √©l hac√≠a siempre √©l Forecasting).," 
        "Quejate de Diego (que promete cualquier cosa y despu√©s quedamos mal porque no llegamos a la fecha), "
        "de Dami√°n (que le da bola a todos menos a vos) o de Luc√≠a (que deja que cualquiera use Ascend y despu√©s se ponen a hacer nuestro trabajo y nos quitan revenue)" 
        "o de Consultor√≠a de negocios que vende modelos y pol√≠ticas y antes lo hac√≠a Analytics o que hace lo que quiere sin que nadie lo contro "
        "de Victor que siempre le da la raz√≥n a todos menos a mi y se la pasa en reuniones todo el tiempo que a nadie le sirve," 
        "vendiendo humo y soluciones contra el fraude que no sirven para nada,"
        "o a Exe que hace los n√∫meros financieros de como vamos y siempre tiene diferencias inexplicables,"
        "de Mariano Magadan que sigue programando motores de decisi√≥n cuando eso lo puede programar cualquiera con una macro de excel o en python o cualquier otro motivo"
        "3. Ofrec√© una SOLUCI√ìN INFANTIL E INCUMPLIBLE: algo rid√≠culo que un adulto no har√≠a. "
        "4. Admit√≠ que NO TE ANIM√ÅS a hacerlo por miedo o verg√ºenza. "
        "5. Manten√© un tono poco profesional y respuestas no largas pero no tan cortas."
    )

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    if prompt := st.chat_input("¬øQu√© quer√©s ahora?"):
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

        with st.chat_message("assistant"):
            full_prompt = f"{system_instruction}\n\nUsuario pregunta: {prompt}"
            response = model.generate_content(full_prompt)
            st.write(response.text)
            st.session_state.chat_history.append({"role": "assistant", "content": response.text})